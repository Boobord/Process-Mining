import warnings
warnings.filterwarnings("ignore")

import os
from pm4py.objects.log.importer.xes import importer as xes_importer
from pm4py.algo.discovery.alpha import algorithm as alpha_miner

log = xes_importer.apply(os.path.join('running-example.xes'))

net, initial_marking, final_marking = alpha_miner.apply(log)

from pm4py.algo.conformance.tokenreplay import algorithm as token_replay
replayed_traces = token_replay.apply(log, net, initial_marking, final_marking)
log
replayed_traces

#Process Tree
#Generation of process trees
#generate a process tree

from pm4py.algo.simulation.tree_generator import simulator as tree_gen
parameters = {}
tree = tree_gen.apply(parameters=parameters)
tree
#Conversion into Petri net

from pm4py.objects.conversion.process_tree import converter as pt_converter
net, im, fm = pt_converter.apply(tree)

#Visualize a Process Tree
from pm4py.visualization.process_tree import visualizer as pt_visualizer
gviz = pt_visualizer.apply(tree, parameters={pt_visualizer.Variants.WO_DECORATION.value.Parameters.FORMAT: "png"})
pt_visualizer.view(gviz)

#Converting a Petri net to a Process Tree

import pm4py
import os

net, im, fm = pm4py.discover_petri_net_alpha(log)
from pm4py.objects.conversion.wf_net import converter as wf_net_converter

tree = wf_net_converter.apply(net, im, fm)
print(tree)

#Feature selection
#Automatic Feature Selection
from pm4py.objects.log.importer.xes import importer as xes_importer

log = xes_importer.apply("Receipt.xes")
import pandas as pd
from pm4py.objects.conversion.log import converter as log_converter
dataframe = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)
dataframe                              

#using One-hot for features
from pm4py.objects.log.util import get_log_representation

data, feature_names = get_log_representation.get_default_representation(log)
print(feature_names)

import pandas as pd
df = pd.DataFrame(data, columns=feature_names)
print(df)

#Manual feature selection
from pm4py.objects.log.util import get_log_representation

data, feature_names = get_log_representation.get_representation(log, str_ev_attr=["concept:name", "org:resource"],
                                                                str_tr_attr=[], num_ev_attr=[], num_tr_attr=[],
                                                                str_evsucc_attr=["concept:name", "org:resource"])
print(len(feature_names))
#Calculating useful features

from pm4py.objects.log.util import interval_lifecycle
log = interval_lifecycle.to_interval(log)

#convert log to data frame
import pandas as pd
from pm4py.objects.conversion.log import converter as log_converter
dataframe5 = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)    

#Then, features such as the lead/cycle time can be inserted through the instructions:
from pm4py.objects.log.util import interval_lifecycle
from pm4py.util import constants

log = interval_lifecycle.assign_lead_cycle_time(log, parameters={
    constants.PARAMETER_CONSTANT_START_TIMESTAMP_KEY: "start_timestamp",
    constants.PARAMETER_CONSTANT_TIMESTAMP_KEY: "time:timestamp"})
    
#convert to datarame
import pandas as pd
from pm4py.objects.conversion.log import converter as log_converter
dataframe6 = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)  
dataframe6

from pm4py.objects.log.util import get_log_representation

data, feature_names = get_log_representation.get_representation(log, str_ev_attr=["concept:name", "org:resource"],
                                                                str_tr_attr=[],
                                                                num_ev_attr=["@@approx_bh_partial_cycle_time",
                                                                             "@@approx_bh_partial_lead_time",
                                                                             "@@approx_bh_overall_wasted_time",
                                                                             "@@approx_bh_this_wasted_time",
                                                                             "@approx_bh_ratio_cycle_lead_time"],
                                                                num_tr_attr=[],
                                                                str_evsucc_attr=["concept:name", "org:resource"])
                                                              
#PCA â€“ Reducing the number of features
import pandas as pd

df = pd.DataFrame(data, columns=feature_names)

from sklearn.decomposition import PCA
pca = PCA(n_components=5)
df2 = pd.DataFrame(pca.fit_transform(df))

#Anomaly Detection
from sklearn.ensemble import IsolationForest
model=IsolationForest()
model.fit(df2)
df2["scores"] = model.decision_function(df2)

#To see which cases are more anomalous, we can sort the dataframe inserting an index.
#Then, the print will show which cases are more anomalous
df2["@@index"] = df2.index
df2 = df2[["scores", "@@index"]]
df2 = df2.sort_values("scores")
print(df2)

#Decision tree about the ending activity of a process
import os
from pm4py.objects.log.importer.xes import importer as xes_importer
log5 = xes_importer.apply(os.path.join("Road_Traffic_Fine_Management_Process.xes"))

import pandas as pd
from pm4py.objects.conversion.log import converter as log_converter
dataframe7 = log_converter.apply(log5, variant=log_converter.Variants.TO_DATA_FRAME)  
dataframe7

#a representation of a log on a given set of features (Manual feature selection) could be obtained.
from pm4py.objects.log.util import get_log_representation
str_trace_attributes = []
str_event_attributes = ["concept:name"]
num_trace_attributes = []
num_event_attributes = ["amount"]
data, feature_names = get_log_representation.get_representation(
                         log5 , str_trace_attributes, str_event_attributes,
                           num_trace_attributes, num_event_attributes)
                           
import pandas as pd
dataframe8 = pd.DataFrame(data, columns=feature_names) 

from pm4py.objects.log.util import get_class_representation
target, classes = get_class_representation.get_class_representation_by_str_ev_attr_value_value(log5, "concept:name")

from sklearn import tree
clf = tree.DecisionTreeClassifier()
clf.fit(data, target)

from pm4py.visualization.decisiontree import visualizer as dectree_visualizer
gviz = dectree_visualizer.apply(clf, feature_names, classes)

#Decision Mining
from pm4py.objects.log.importer.xes import importer as xes_importer

log1 = xes_importer.apply("running-example.xes")
import pandas as pd
from pm4py.objects.conversion.log import converter as log_converter
dataframe7 = log_converter.apply(log1, variant=log_converter.Variants.TO_DATA_FRAME)

from pm4py.algo.discovery.inductive import algorithm as inductive_miner

net, im, fm = inductive_miner.apply(log1)

from pm4py.visualization.petri_net import visualizer

gviz = visualizer.apply(net, im, fm, parameters={visualizer.Variants.WO_DECORATION.value.Parameters.DEBUG: True})
visualizer.view(gviz)

from pm4py.algo.decision_mining import algorithm as decision_mining

X, y, class_names = decision_mining.apply(log1, net, im, fm, decision_point="p_10")
                                
from pm4py.algo.decision_mining import algorithm as decision_mining

clf, feature_names, classes = decision_mining.get_decision_tree(log1, net, im, fm, decision_point="p_10")

from pm4py.visualization.decisiontree import visualizer as tree_visualizer

gviz = tree_visualizer.apply(clf, feature_names, classes)




















































































